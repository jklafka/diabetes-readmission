{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sacred-habitat",
   "metadata": {},
   "source": [
    "# Diabetes 130-US hospitals for years 1999-2008 Data Set\n",
    "\n",
    "## Data Set Information:\n",
    "\n",
    "The dataset represents 10 years (1999-2008) of clinical care at 130 US hospitals and integrated delivery networks. It includes over 50 features representing patient and hospital outcomes. Information was extracted from the database for encounters that satisfied the following criteria.\n",
    "(1) It is an inpatient encounter (a hospital admission).\n",
    "(2) It is a diabetic encounter, that is, one during which any kind of diabetes was entered to the system as a diagnosis.\n",
    "(3) The length of stay was at least 1 day and at most 14 days.\n",
    "(4) Laboratory tests were performed during the encounter.\n",
    "(5) Medications were administered during the encounter.\n",
    "The data contains such attributes as patient number, race, gender, age, admission type, time in hospital, medical specialty of admitting physician, number of lab test performed, HbA1c test result, diagnosis, number of medication, diabetic medications, number of outpatient, inpatient, and emergency visits in the year before the hospitalization, etc.\n",
    "\n",
    "## Bibliography\n",
    "\n",
    "Beata Strack, Jonathan P. DeShazo, Chris Gennings, Juan L. Olmo, Sebastian Ventura, Krzysztof J. Cios, and John N. Clore, “Impact of HbA1c Measurement on Hospital Readmission Rates: Analysis of 70,000 Clinical Database Patient Records,” BioMed Research International, vol. 2014, Article ID 781670, 11 pages, 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "running-psychiatry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-coffee",
   "metadata": {},
   "source": [
    "## train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "copyrighted-accessory",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"numeric_data.csv\").dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rough-spiritual",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get model preprocessing and work stuff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "macro-snapshot",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(train.drop(\"readmitted\", axis=1), train[\"readmitted\"], \\\n",
    "                                                test_size = 0.20, train_size = 0.80, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "blind-forge",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(Xtrain)\n",
    "Xtrainscaled = scaler.transform(Xtrain)\n",
    "Xtestscaled = scaler.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acute-comedy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6171550465925676"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## logistic regression classifier\n",
    "reg = LogisticRegression(solver = \"liblinear\", penalty = \"l1\").fit(Xtrain, ytrain)\n",
    "reg.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "announced-prime",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6082856180532166"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier().fit(Xtrain, ytrain)\n",
    "mlp.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "offshore-workplace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6054788368698776"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC().fit(Xtrain, ytrain)\n",
    "svc.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "destroyed-literature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6018861569552038"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier().fit(Xtrain, ytrain)\n",
    "rfc.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hundred-round",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5351970360390704"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier().fit(Xtrain, ytrain)\n",
    "dtc.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "earlier-belle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5668575277871337"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier().fit(Xtrain, ytrain)\n",
    "knn.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-marijuana",
   "metadata": {},
   "source": [
    "## GridSearch cross-validation across parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-forth",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-emperor",
   "metadata": {},
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-career",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
